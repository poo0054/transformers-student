# é¦–å…ˆåŠ è½½ Yelp è¯„è®ºæ•°æ®é›†ï¼š
import evaluate
import numpy as np
from datasets import load_dataset
from transformers import AutoModelForSequenceClassification
from transformers import AutoTokenizer
from transformers import TrainingArguments, Trainer

dataset = load_dataset("yelp_review_full")
# æ­£å¦‚æ‚¨ç°åœ¨æ‰€çŸ¥ï¼Œæ‚¨éœ€è¦ä¸€ä¸ªåˆ†è¯å™¨æ¥å¤„ç†æ–‡æœ¬ï¼Œå¹¶åŒ…å«å¡«å……å’Œæˆªæ–­ç­–ç•¥æ¥å¤„ç†ä»»ä½•å¯å˜åºåˆ—é•¿åº¦ã€‚è¦ä¸€æ­¥å¤„ç†æ•°æ®é›†ï¼Œè¯·ä½¿ç”¨ ğŸ¤— Datasets map æ–¹æ³•å¯¹æ•´ä¸ªæ•°æ®é›†åº”ç”¨é¢„å¤„ç†å‡½æ•°ï¼š

tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-cased")


def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)


tokenized_datasets = dataset.map(tokenize_function, batched=True)

print(tokenized_datasets)
small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))

# é¦–å…ˆåŠ è½½æ¨¡å‹å¹¶æŒ‡å®šé¢„æœŸæ ‡ç­¾çš„æ•°é‡ã€‚ä» Yelp Review æ•°æ®é›†å¡ä¸­ï¼Œæ‚¨çŸ¥é“æœ‰äº”ä¸ªæ ‡ç­¾ï¼š


model = AutoModelForSequenceClassification.from_pretrained("google-bert/bert-base-cased", num_labels=5)

# æŒ‡å®šä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹çš„ä½ç½®ï¼š
training_args = TrainingArguments(output_dir="E:/cache/test_trainer")

# Trainer åœ¨è®­ç»ƒæœŸé—´ä¸ä¼šè‡ªåŠ¨è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚æ‚¨éœ€è¦å‘ Trainer ä¼ é€’ä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—å’ŒæŠ¥å‘ŠæŒ‡æ ‡ã€‚
# ğŸ¤— Evaluate åº“æä¾›äº†ä¸€ä¸ªç®€å•çš„ accuracy å‡½æ•°ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ evaluate.load ï¼ˆè¯·å‚é˜…æ­¤å¿«é€Ÿæ•™ç¨‹äº†è§£æ›´å¤šä¿¡æ¯ï¼‰å‡½æ•°åŠ è½½ï¼š


metric = evaluate.load("accuracy")


# å¯¹ metric è°ƒç”¨ compute ä»¥è®¡ç®—æ‚¨çš„é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚åœ¨å°†é¢„æµ‹ä¼ é€’ç»™ compute ä¹‹å‰ï¼Œæ‚¨éœ€è¦å°† logits è½¬æ¢ä¸ºé¢„æµ‹ï¼ˆè®°ä½æ‰€æœ‰ ğŸ¤— Transformers æ¨¡å‹éƒ½è¿”å› logitsï¼‰ï¼š
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)


# å¦‚æœæ‚¨æƒ³åœ¨å¾®è°ƒæœŸé—´ç›‘æ§è¯„ä¼°æŒ‡æ ‡ï¼Œè¯·åœ¨è®­ç»ƒå‚æ•°ä¸­æŒ‡å®š evaluation_strategy å‚æ•°ï¼Œä»¥åœ¨æ¯ä¸ªå‘¨æœŸç»“æŸæ—¶æŠ¥å‘Šè¯„ä¼°æŒ‡æ ‡ï¼š


training_args = TrainingArguments(output_dir="test_trainer", evaluation_strategy="epoch")

# ä½¿ç”¨æ‚¨çš„æ¨¡å‹ã€è®­ç»ƒå‚æ•°ã€è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ä»¥åŠè¯„ä¼°å‡½æ•°åˆ›å»ºä¸€ä¸ª Trainer å¯¹è±¡ï¼š
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
)

trainer.train()
