from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

# åœ¨æˆ‘ä»¬å®šä¹‰æˆ‘ä»¬çš„ Trainer ä¹‹å‰é¦–å…ˆè¦å®šä¹‰ä¸€ä¸ª TrainingArguments ç±»ï¼Œå®ƒå°†åŒ…å« Trainerç”¨äºè®­ç»ƒå’Œè¯„ä¼°çš„æ‰€æœ‰è¶…å‚æ•°ã€‚
# æ‚¨å”¯ä¸€å¿…é¡»æä¾›çš„å‚æ•°æ˜¯ä¿å­˜è®­ç»ƒæ¨¡å‹çš„ç›®å½•ï¼Œä»¥åŠè®­ç»ƒè¿‡ç¨‹ä¸­çš„æ£€æŸ¥ç‚¹ã€‚å¯¹äºå…¶ä½™çš„å‚æ•°ï¼Œæ‚¨å¯ä»¥ä¿ç•™é»˜è®¤å€¼ï¼Œè¿™å¯¹äºåŸºæœ¬å¾®è°ƒåº”è¯¥éå¸¸æœ‰æ•ˆã€‚
from transformers import TrainingArguments

training_args = TrainingArguments("test-trainer")

# ç¬¬äºŒæ­¥æ˜¯å®šä¹‰æˆ‘ä»¬çš„æ¨¡å‹ã€‚æ­£å¦‚åœ¨[ä¹‹å‰çš„ç« èŠ‚](/2_Using Transformers/Introduction)ä¸€æ ·ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ AutoModelForSequenceClassification ç±»ï¼Œå®ƒæœ‰ä¸¤ä¸ªå‚æ•°ï¼š

from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)

from transformers import Trainer

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
)

trainer.train()

# è¯„ä¼°
# è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•æ„å»ºä¸€ä¸ªæœ‰ç”¨çš„ compute_metrics() å‡½æ•°å¹¶åœ¨æˆ‘ä»¬ä¸‹æ¬¡è®­ç»ƒæ—¶ä½¿ç”¨å®ƒã€‚
# è¯¥å‡½æ•°å¿…é¡»é‡‡ç”¨ EvalPrediction å¯¹è±¡ï¼ˆå¸¦æœ‰ predictions å’Œ label_ids å­—æ®µçš„å‚æ•°å…ƒç»„ï¼‰å¹¶å°†è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²åˆ°æµ®ç‚¹æ•°çš„å­—å…¸ï¼ˆå­—ç¬¦ä¸²æ˜¯è¿”å›çš„æŒ‡æ ‡çš„åç§°ï¼Œè€Œæµ®ç‚¹æ•°æ˜¯å®ƒä»¬çš„å€¼ï¼‰ã€‚
# æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Trainer.predict() å‘½ä»¤æ¥ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼š

predictions = trainer.predict(tokenized_datasets["validation"])
# predict() çš„è¾“å‡ºç»“æœæ˜¯å…·æœ‰ä¸‰ä¸ªå­—æ®µçš„å‘½åå…ƒç»„ï¼š predictions , label_ids ï¼Œ å’Œ metrics .è¿™ metrics å­—æ®µå°†åªåŒ…å«ä¼ é€’çš„æ•°æ®é›†çš„ loss ï¼Œ
# ä»¥åŠä¸€äº›è¿è¡Œæ—¶é—´ï¼ˆé¢„æµ‹æ‰€éœ€çš„æ€»æ—¶é—´å’Œå¹³å‡æ—¶é—´ï¼‰ã€‚å¦‚æœæˆ‘ä»¬å®šä¹‰äº†è‡ªå·±çš„ compute_metrics() å‡½æ•°å¹¶å°†å…¶ä¼ é€’ç»™ Trainer ï¼Œè¯¥å­—æ®µè¿˜å°†åŒ…å« compute_metrics()çš„ç»“æœã€‚
print(predictions.predictions.shape, predictions.label_ids.shape, predictions.metrics)

# predict() æ–¹æ³•æ˜¯å…·æœ‰ä¸‰ä¸ªå­—æ®µçš„å‘½åå…ƒç»„ï¼š predictions , label_ids ï¼Œ å’Œ metrics .è¿™ metrics å­—æ®µå°†åªåŒ…å«ä¼ é€’çš„æ•°æ®é›†çš„ lossï¼Œä»¥åŠä¸€äº›è¿è¡Œæ—¶é—´ï¼ˆé¢„æµ‹æ‰€éœ€çš„æ€»æ—¶é—´å’Œå¹³å‡æ—¶é—´ï¼‰ã€‚
# å¦‚æœæˆ‘ä»¬å®šä¹‰äº†è‡ªå·±çš„ compute_metrics() å‡½æ•°å¹¶å°†å…¶ä¼ é€’ç»™ Trainer ï¼Œè¯¥å­—æ®µè¿˜å°†åŒ…å«compute_metrics() çš„ç»“æœã€‚
# å¦‚ä½ çœ‹åˆ°çš„ï¼Œ predictions æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º 408 x 2 çš„äºŒç»´æ•°ç»„ï¼ˆ408 æ˜¯æˆ‘ä»¬ä½¿ç”¨çš„æ•°æ®é›†ä¸­å…ƒç´ çš„æ•°é‡ï¼‰ã€‚
# è¿™äº›æ˜¯æˆ‘ä»¬ä¼ é€’ç»™predict()çš„æ•°æ®é›†çš„æ¯ä¸ªå…ƒç´ çš„ç»“æœ( logits )ï¼ˆæ­£å¦‚ä½ åœ¨ä¹‹å‰çš„ç« èŠ‚çœ‹åˆ°çš„æƒ…å†µï¼‰ã€‚è¦å°†æˆ‘ä»¬çš„é¢„æµ‹çš„å¯ä»¥ä¸çœŸæ­£çš„æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬éœ€è¦åœ¨ç¬¬äºŒä¸ªè½´ä¸Šå–æœ€å¤§å€¼çš„ç´¢å¼•ï¼š
import numpy as np

preds = np.argmax(predictions.predictions, axis=-1)

# ç°åœ¨å»ºç«‹æˆ‘ä»¬çš„ compute_metric() å‡½æ•°æ¥è¾ƒä¸ºç›´è§‚åœ°è¯„ä¼°æ¨¡å‹çš„å¥½åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ ğŸ¤— Evaluate åº“ä¸­çš„æŒ‡æ ‡ã€‚
# æˆ‘ä»¬å¯ä»¥åƒåŠ è½½æ•°æ®é›†ä¸€æ ·è½»æ¾åŠ è½½ä¸ MRPC æ•°æ®é›†å…³è”çš„æŒ‡æ ‡ï¼Œè¿™æ¬¡ä½¿ç”¨ evaluate.load() å‡½æ•°ã€‚
# è¿”å›çš„å¯¹è±¡æœ‰ä¸€ä¸ª compute()æ–¹æ³•æˆ‘ä»¬å¯ä»¥ç”¨æ¥è¿›è¡Œåº¦é‡è®¡ç®—çš„æ–¹æ³•ï¼š
import evaluate

metric = evaluate.load("glue", "mrpc")
compute = metric.compute(predictions=preds, references=predictions.label_ids)
print(compute)

pt_save_directory = "D:/cache/model/demo1"
tokenizer.save_pretrained(pt_save_directory)
model.save_pretrained(pt_save_directory)
