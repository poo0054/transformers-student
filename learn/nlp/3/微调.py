from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

# å®šä¹‰ Trainer ä¹‹å‰çš„ç¬¬ä¸€æ­¥æ˜¯å®šä¹‰ä¸€ä¸ª TrainingArguments ç±»ï¼Œè¯¥ç±»å°†åŒ…å« Trainer å°†ç”¨äºè®­ç»ƒå’Œè¯„ä¼°çš„æ‰€æœ‰è¶…å‚æ•°ã€‚
# æ‚¨å¿…é¡»æä¾›çš„å”¯ä¸€å‚æ•°æ˜¯ä¿å­˜è®­ç»ƒæ¨¡å‹çš„ç›®å½•ï¼Œä»¥åŠæ²¿é€”çš„æ£€æŸ¥ç‚¹ã€‚å¯¹äºæ‰€æœ‰å…¶ä»–æ“ä½œï¼Œæ‚¨å¯ä»¥ä¿ç•™é»˜è®¤å€¼ï¼Œè¿™åº”è¯¥å¯ä»¥å¾ˆå¥½åœ°è¿›è¡ŒåŸºæœ¬çš„å¾®è°ƒã€‚
from transformers import TrainingArguments

training_args = TrainingArguments("ttt-trainer")

# ç¬¬äºŒæ­¥æ˜¯å®šä¹‰æˆ‘ä»¬çš„æ¨¡å‹ã€‚ä¸ä¸Šä¸€ç« ä¸€æ ·ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å…·æœ‰ä¸¤ä¸ªæ ‡ç­¾çš„ AutoModelForSequenceClassification ç±»ï¼š
from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)

from transformers import Trainer

# ä¸€æ—¦æœ‰äº†æ¨¡å‹ï¼Œæˆ‘ä»¬å°±å¯ä»¥å®šä¹‰ä¸€ä¸ª Trainerï¼Œæ–¹æ³•æ˜¯å°†åˆ°ç›®å‰ä¸ºæ­¢æ„å»ºçš„æ‰€æœ‰å¯¹è±¡
# ï¼ˆæ¨¡å‹ã€training_argsã€è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†ã€data_collator å’Œ tokenizerï¼‰ä¼ é€’ç»™å®ƒï¼š
trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
)
# è¦åœ¨æˆ‘ä»¬çš„æ•°æ®é›†ä¸Šå¾®è°ƒæ¨¡å‹ï¼Œæˆ‘ä»¬åªéœ€è¦è°ƒç”¨ Trainer çš„ trainï¼ˆï¼‰ æ–¹æ³•ï¼š
trainer.train()

# è¿™å°†å¼€å§‹å¾®è°ƒï¼ˆåœ¨ GPU ä¸Šåº”è¯¥éœ€è¦å‡ åˆ†é’Ÿï¼‰å¹¶æ¯ 500 æ­¥æŠ¥å‘Šä¸€æ¬¡è®­ç»ƒæŸå¤±ã€‚ä½†æ˜¯ï¼Œå®ƒä¸ä¼šå‘Šè¯‰æ‚¨æ¨¡å‹çš„æ€§èƒ½å¦‚ä½•ï¼ˆæˆ–å·®ï¼‰ã€‚è¿™æ˜¯å› ä¸ºï¼š
# æˆ‘ä»¬æ²¡æœ‰å‘Šè¯‰ Trainer åœ¨è®­ç»ƒæœŸé—´è¿›è¡Œè¯„ä¼°ï¼Œè€Œæ˜¯å°†evaluation_strategyè®¾ç½®ä¸ºâ€œstepsâ€ï¼ˆæ¯ eval_stepsè¯„ä¼°ä¸€æ¬¡ï¼‰æˆ– â€œepochâ€ï¼ˆåœ¨æ¯ä¸ª epoch ç»“æŸæ—¶è¯„ä¼°ï¼‰ã€‚
# æˆ‘ä»¬æ²¡æœ‰ä¸º Trainer æä¾› compute_metricsï¼ˆï¼‰ å‡½æ•°æ¥è®¡ç®—æ‰€è¿°è¯„ä¼°æœŸé—´çš„æŒ‡æ ‡ï¼ˆå¦åˆ™è¯„ä¼°åªä¼šæ‰“å°æŸå¤±ï¼Œè¿™ä¸æ˜¯ä¸€ä¸ªéå¸¸ç›´è§‚çš„æ•°å­—ï¼‰ã€‚

# è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•æ„å»ºä¸€ä¸ªæœ‰ç”¨çš„ compute_metricsï¼ˆï¼‰ å‡½æ•°å¹¶åœ¨ä¸‹æ¬¡è®­ç»ƒæ—¶ä½¿ç”¨å®ƒã€‚
# è¯¥å‡½æ•°å¿…é¡»é‡‡ç”¨ EvalPrediction å¯¹è±¡ï¼ˆè¯¥å¯¹è±¡æ˜¯å…·æœ‰ predictions å­—æ®µå’Œ label_ids å­—æ®µçš„å‘½åå…ƒç»„ï¼‰ï¼Œ
# å¹¶å°†è¿”å›å°†å­—ç¬¦ä¸²æ˜ å°„åˆ°æµ®ç‚¹æ•°çš„å­—å…¸ï¼ˆå­—ç¬¦ä¸²æ˜¯è¿”å›çš„æŒ‡æ ‡çš„åç§°ï¼Œæµ®ç‚¹æ•°æ˜¯å…¶å€¼ï¼‰ã€‚
# è¦ä»æˆ‘ä»¬çš„æ¨¡å‹ä¸­è·å¾—ä¸€äº›é¢„æµ‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Trainer.predictï¼ˆï¼‰ å‘½ä»¤ï¼š
predictions = trainer.predict(tokenized_datasets["validation"])
print(predictions.predictions.shape, predictions.label_ids.shape)
# predictï¼ˆï¼‰ æ–¹æ³•çš„è¾“å‡ºæ˜¯å¦ä¸€ä¸ªå‘½åå…ƒç»„ï¼Œå…¶ä¸­åŒ…å«ä¸‰ä¸ªå­—æ®µï¼špredictionsã€label_ids å’Œ metricsã€‚
# metrics å­—æ®µå°†ä»…åŒ…å«æ‰€ä¼ é€’æ•°æ®é›†çš„æŸå¤±ï¼Œä»¥åŠä¸€äº›æ—¶é—´æŒ‡æ ‡ï¼ˆé¢„æµ‹æ€»æ—¶é—´å’Œå¹³å‡å€¼ï¼‰ã€‚
# å®Œæˆ compute_metricsï¼ˆï¼‰ å‡½æ•°å¹¶å°†å…¶ä¼ é€’ç»™ Trainer åï¼Œè¯¥å­—æ®µè¿˜å°†åŒ…å« compute_metricsï¼ˆï¼‰ è¿”å›çš„æŒ‡æ ‡ã€‚


# å¦‚æ‚¨æ‰€è§ï¼Œpredictions æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º 408 x 2 çš„äºŒç»´æ•°ç»„ï¼ˆ408 æ˜¯æˆ‘ä»¬ä½¿ç”¨çš„æ•°æ®é›†ä¸­çš„å…ƒç´ æ•°ï¼‰ã€‚
# è¿™äº›æ˜¯æˆ‘ä»¬ä¼ é€’ç»™ predictï¼ˆï¼‰ çš„æ•°æ®é›†çš„æ¯ä¸ªå…ƒç´ çš„ logitsï¼ˆæ­£å¦‚æ‚¨åœ¨ä¸Šä¸€ç« ä¸­çœ‹åˆ°çš„ï¼Œæ‰€æœ‰ Transformer æ¨¡å‹éƒ½è¿”å› logitsï¼‰ã€‚
# è¦å°†å®ƒä»¬è½¬æ¢ä¸ºæˆ‘ä»¬å¯ä»¥ä¸æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒçš„é¢„æµ‹ï¼Œæˆ‘ä»¬éœ€è¦åœ¨ç¬¬äºŒä¸ªè½´ä¸Šè·å–å…·æœ‰æœ€å¤§å€¼çš„ç´¢å¼•ï¼š
import numpy as np

preds = np.argmax(predictions.predictions, axis=-1)

# æˆ‘ä»¬ç°åœ¨å¯ä»¥å°†è¿™äº› preds ä¸æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒã€‚ä¸ºäº†æ„å»ºæˆ‘ä»¬çš„ compute_metricï¼ˆï¼‰ å‡½æ•°ï¼Œæˆ‘ä»¬å°†ä¾èµ– Evaluate åº“ä¸­çš„ğŸ¤—æŒ‡æ ‡ã€‚
# æˆ‘ä»¬å¯ä»¥åƒåŠ è½½æ•°æ®é›†ä¸€æ ·è½»æ¾åœ°åŠ è½½ä¸ MRPC æ•°æ®é›†ç›¸å…³çš„æŒ‡æ ‡ï¼Œè¿™æ¬¡ä½¿ç”¨ evaluate.loadï¼ˆï¼‰ å‡½æ•°ã€‚
# è¿”å›çš„å¯¹è±¡æœ‰ä¸€ä¸ª tableï¼ˆï¼‰ æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®ƒæ¥æ‰§è¡Œåº¦é‡è®¡ç®—ï¼š

import evaluate

metric = evaluate.load("glue", "mrpc")
compute = metric.compute(predictions=preds, references=predictions.label_ids)
print("compute", compute)


# æ‚¨è·å¾—çš„ç¡®åˆ‡ç»“æœå¯èƒ½ä¼šæœ‰æ‰€ä¸åŒï¼Œå› ä¸ºæ¨¡å‹å¤´çš„éšæœºåˆå§‹åŒ–å¯èƒ½ä¼šæ”¹å˜å®ƒå®ç°çš„æŒ‡æ ‡ã€‚

# åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„å‡†ç¡®ç‡ä¸º 85.78%ï¼ŒF1 åˆ†æ•°ä¸º 89.97ã€‚
# è¿™æ˜¯ç”¨äºè¯„ä¼° GLUE åŸºå‡†æµ‹è¯•çš„ MRPC æ•°æ®é›†ç»“æœçš„ä¸¤ä¸ªæŒ‡æ ‡ã€‚BERT è®ºæ–‡ä¸­çš„è¡¨æ ¼æŠ¥å‘Šäº†åŸºæœ¬æ¨¡å‹çš„ F1 åˆ†æ•°ä¸º 88.9ã€‚
# è¿™æ˜¯æˆ‘ä»¬ç›®å‰ä½¿ç”¨æœ‰å¤–å£³æ¨¡å‹æ—¶çš„æ— å¤–å£³æ¨¡å‹ï¼Œè¿™è§£é‡Šäº†æ›´å¥½çš„ç»“æœã€‚

# å°†æ‰€æœ‰å†…å®¹æ‰“åŒ…åœ¨ä¸€èµ·ï¼Œæˆ‘ä»¬å¾—åˆ° compute_metricsï¼ˆï¼‰ å‡½æ•°ï¼š
def compute_metrics(eval_preds):
    metric = evaluate.load("glue", "mrpc")
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)
